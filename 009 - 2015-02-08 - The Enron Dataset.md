| Person | Transcripts |
| :-- | :-- |
| Ben: | OK. So um, do you have a favourite dataset? |
| Katie: | A data set that one works with they're like children? You shouldn't have a favoruite but there are some that are very special to you. |
| Ben: |  OK. We’re going to talk about one of those. You are listening to linear digressions. |
| Ben: | Alright. So, what’s our dataset? |
| Katie: | It’s the Enron emails Corpus. Ya so if there's anyone listening who took the Intro to Machine Learning, you know a lot about this dataset, this was … . |
| Ben: | That’s a course that we have in Udacity. It’s the company who... we work for and lets us put this together, so hey! |
| Katie: | Thanks guys! |
| Ben: | And you taught it too. |
| Katie: | I taught the Intro To Machine Learning course, yeah and in the course of that... was... I knew about the Enron emails before but for that class, that was the first time I really dug into it. |
| Ben: | That's when it became a little dataset child? |
| Katie: | Oh yeah, and I really grew to love it and made it my own in some pretty particular ways, and yes, so the project that we tried to deal with is this dataset. Well we should back up a little bit. |
| Ben: | Yeah. Let's back up. What is this dataset exactly? |
| Katie: | So, do you remember Enron? |
| Ben: | I do. |
| Katie: | We're both old enough to remember Enron. |
| Ben: | Yes, an oil company. |
| Katie: | It was an energy distribution company really. |
| Ben: | Oh, okay, I guess I don't remember well enough. |
| Katie: | Well, no. It's an easy mistake to make, Ben, because they did all kinds of stuff, much of which was pretty fraudulent. |
| Ben: | I see. |
| Katie: | And so, it was a huge copy, it was a very big company, it’s a very well-respected company. I think at its height it was the seventh biggest company in the United States. |
| Ben: | Wa, so very very very big? |
| Katie: | Yes, yes, and took a lot of pride in the smartest of the people who work there and their ability to make lots and lots of money and all that sort of thing. In 2001 and 2002, the company went bankrupt, in a blizzard of fraud, there was all kinds of different stuff that was going on. And it was one of the biggest, it was a big political story obviously, it was a huge economic story. There were tens of thousands of people who lost their jobs, who lost huge amounts of money, when the stock became worthless and so... as would be expected, there was a big federal investigation into the fraud to try to figure out exactly what happened. Lots of people ended up going to jail or being indicted, and in the course of the investigation that happened, they seized the email inboxes of about 150 of the senior executives. |
| Ben: | Woo. Okay. |
| Katie: | Those emails were turned into a dataset that we today know as the Enron Email Corpus. |
| Ben: | Wa. So... so, I can go and download the Enron emails Corpus and look at what the top 150 executives of Enron in 2000-whatever did? |
| Katie: | You can, absolutely. Yeah, you can read these guys’ inboxes. |
| Ben: | That’s crazy, that is insane, like that from our perspective today, the idea of just releasing all of the data in any person's email inbox, it’s insane... like because there's data mining, there's all kinds of privacy, potential privacy issues. |
| Katie: | I think there's much more of an awareness now, yes, of how much personal stuff can be in your email messages. |
| Ben: | Even if you're not explicitly saying these things you can infer a lot. |
| Katie: | Yeah, and in this particular case there was stuff that they just had never even really thought about before they released it, so one of the things that this Corpus has been used for is as an example to write algorithms that clean up personally identifiable information and datasets. So when this was originally released, it was in more or less its raw form, with only some fairly minor cleaning up, and the people realized their social security numbers in here, there's bank information, there’s, you know, birthdays and mother...maid, mothers’ maiden names, so you could easily steal someone's identity. And I should say that even though Enron, there was a lot of fraud going on in Enron, most of the people of Enron weren't involved in fraud right? It’s totally conceivable that you could just have your emails swept up in this in this Dragnet even though you're doing nothing wrong and then you can kind of have it ruined all over again because all of a sudden everybody knows your wife's name and your address and your social security number. And this has been one of the uses for it actually is they used it to help develop algorithms that can scrub this sort of information out of datasets. |
| Ben: | That's interesting. So... so, presumably because this has been around for so long and because so many people have looked at it and spent time cleaning it up. It's basically a huge label dataset in this sense, right? |
| Katie: | Label in what way? |
| Ben: | Label in that you know what all the information in the dataset is personally identifiable information and from that you can figure out what personally identifiable information looks like. |
| Katie: | So a question: I don't know if it works exactly that way because I think if you were to go online right now and just download this dataset, what you would find is a version of the corpus where all this information had been scrubbed away. |
| Ben: | Oh I see. |
| Katie: | And so if you had a version of the dataset that was many years older than maybe had more messages in it, then you could do a comparison of these two datasets and sort of figure out what had gone missing and then figure out if that's personally identifiable information. But, yeah, the companies that work on algorithms like this, this is absolutely one of the the training grounds that they say, they were able to find and remove whatever percentage of personally identifiable information from this very famous Corpus, it’s almost like a benchmark at this point: how well you can do on the Corpus. |
| Ben: | So in the process of developing the course where you use this data, what kinds of difficulties did you run into in terms of dealing with labeling, in dealing with cleaning up the quality of data and all of that stuff? |
| Katie: | The thing that we are trying to do in that class was to use patterns in the Enron data to predict who was what we call a person of interest in the fraud case. If we identify as a person who was indicted or made some kind of plea arrangement with the government or agreed to testify in exchange for immunity, basically that looks like there was some kind of involvement in the fraud they're on their part, even if they weren't technically found guilty of fraud. And so in order to get that sort of labelled data set, of course you got a bunch of emails. The emails don't say ‘oh, by the way, I'm going to commit some frauds’, something like that, right? |
| Ben: | Yeah, right. |
| Katie: | So you have to... you have to go out and you have to get those labels so I just spent a couple hours with Vintage New York Times, coming up with list of all the people who were indicted for various Enron activities and then writing it in by hand. |
| Ben: | So you manually labeled all of that data? |
| Katie: | Yes, yes, which didn't take that long because they were... I think about 35 or so people who were in the word ‘Persons of Interest’ by our definition. So it doesn't take too long to to pick out who those 35 people are and then to enter that information. |
| Katie: | One of the things that was harder was... and this I think is actually completely unique to the Udacity course, this hasn't been done before I did it. In addition to the emails, there was also a lot of confidential financial information that came out. Federal investigators tracked down data from 2000, 2000, 2001 that time about who is getting how much money, and in what... how it was being paid to them, is it salary or bonus or stock, or is somebody selling off much of their stock right before the crash, that's a very strong indicator. So I found a spreadsheet. Well the first thing I did was I read a bunch of news articles that said, ‘oh, there's all this interesting Enron bonus data, you're not going to believe how much this person made’. So I knew the data was out there, I knew it existed. It was fairly non-trivial to find, I don't remember exactly but there was... so it took me a good hour to find the spreadsheet, which was in a PDF format, I had to convert it and I had to go in and manually clean it up. The payoff was, at the end of this, I had another 150 or 200 people that I had all of their financial information and then taking the finance information and the email information and making them together was also a project in and of itself. That’s another few days or week or so to write that is validated, but at the end of it that you have is you have incredibly rich email corpus, this incredibly rich financial information corpus and with all of this data together, you can start to get an idea of what the patterns are that determined who was cooking the books. |
| Ben: | So, that just sounds insane. So, do you think that you are ever going to get a data set like this again? |
| Katie: | No, no. The Enron corpus has taught us a huge amount by the fact that it's out in the wild now. So, people use it to practise topic modeling, these are to  to try to figure out like what people, what topics are people writing about in their emails, trying to figure out automated classification algorithms: can we automatically know what this email is about and like pre-file it in a certain folder for you when it comes in, studying the structure of a large corporation and watching how the structure changes as a function of time. It may be... certain links are going to be stronger or weaker depending on if times are good or if times are bad and people start circling the wagons, sentiment analysis, reading these emails and trying to figure out if people are in good spirits or if they're really, if morales quite low. |
| Ben: | Wow. This is, this is phenomenal. |
| Katie: | It’s an amazing data set. So, we have, it's been the backbone of so many different types of really interesting studies. But I think that, as you pointed out, 2004, 2003 was a different time in terms of the way that we think about people's privacy on the Internet. I think, in the last 10 years we've learned a lot more about just how tenuous your privacy can be and that there are even things you think of is fairly innocuous, aren't? |
| Ben: | Yeah. |
| Katie: | And I think there was some naivete when they released it at first they didn't, there's hundreds of thousands of emails in this Corpus, so nobody had a chance to read them all. But then as soon as you open it up and now there's thousands or tens of thousands of people coming through, they found everything, they found the guy who's cheating on his wife, and they found the guy who was like talking about people behind their back, they found, I don't know, cases of probably employment discrimination, like all the stuff that you sometimes say like emails like cause you think it's private , it's all out there, so no, to answer your question. I don't think there's ever going to be another Enron Dataset, so if this one we have to mine for all it’s worth, but yeah it's a pretty unique dataset. |
| Ben: | So I guess what we're coming back to is... it's really difficult to find such an amazing data set and have it to work with? |
| Katie: | Yeah. Machine learning especially the way we usually think about it, it starts and ends with the data. If you don't have the data, you don't have anything. And if you have really amazing data, then you can... you can do things that you never even would have thought of in the first place. So yeah, the Enron dataset, one of the most famous datasets in the world, deservedly so, em, I don't think there's... there's any email corpus that will threaten it anytime soon. |
| Ben: | Wow. Well thanks for talking more about this. I'm really excited to take your course whatever time. I'm usually busy making courses of my own. |
| Katie: | You will learn a lot about corporate fraud. I’ll tell you that. You didn't think you would, but this is... this is there’s a whole unit on it. |
| Ben: | My gosh. |
