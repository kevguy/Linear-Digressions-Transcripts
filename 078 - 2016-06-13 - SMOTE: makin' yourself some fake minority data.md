| Person | Transcripts |
| :-- | :-- |
| Ben: | Hey Katie. |
| Katie: | Hey Ben. |
| Ben: | What are we talking about today? |
| Katie: | Today we’re talking about SMOTE? |
| Ben: | Smote as in the past tense of smite? |
| Katie: | SMOTE as in synthetic minority something something… I need to find the tab opened in my browser. But… yeah... |
| Ben: | (laughs) Ah… alright. While you hunt for that, I’ll say you are listening to Linear Digressions. |
| Ben: | Did you find your tab? |
| Katie: | Yeah, it stands for Synthetic Minority Oversampling Technique. |
| Ben: | Oh, there's no ‘e’ at the end. |
| Katie: | Well, there’s an ‘e’ after… in ‘technique’... |
| Ben: | Oh geez, wait… is it spelled with an ‘e’? |
| Katie: | Yes. |
| Ben: | Oh, I hate it when... |
| Katie: | But I guess SMOTE’s better than SMOT, right? |
| Ben: | (laughs) SMOT, yeah. Okay so... so paint a picture for me, what's the... what's the problem that this is trying to solve? |
| Katie: | Yeah, so this comes as a little bit from sort of your supervised classification realm. |
| Ben: | Right. |
| Katie: | And one of the things that can happen a lot in supervised classification is that... let's imagine the case was just a binary classifier, so you have two different categories here... you’re trying to sort events into one or another… |
| Ben: | Like… does someone have a disease or does someone not? |
| Katie: | Sure, yeah. Or is this a fraudulent transaction or is this legitimate transaction. |
| Ben: | Yeah, you usually don’t get half fraudulent transactions. |
| Katie: | Well yeah, exactly, that’s where we‘re going with. Sometimes you're fortunate enough that things are fairly evenly balanced between the two classes, but very often this is not the case, one of the cases might be more interesting to you and in particular it might be less frequently found. So in this case, it would be someone who has the disease cuz you could imagine a case in which many people get tested for a disease but only some of them have it, likewise you can imagine that there are many more transactions that are legitimate, than ones that are fraudulent. |
| Ben: | Okay, so basically you've got a lot more thing… a lot more of one thing… and not as much of the other thing... what's the… like what's the problem with that? |
| Katie: | Right, so if you're using one of the standard out-of-the-box supervised classification algorithms, well… very often what happens is it's a little too smart for its own good, and it'll just classify everything as the majority class. And that's not a crazy thing to do cuz it's kind of right if you have something like 99.99% of transactions that are legitimate, then it's pretty easy for a classifier to say, “let's just classify them all as legitimate” because then I'm going to be 99.99% correct. |
| Ben: | Okay, I guess that makes sense, because it's optimizing for the… let’s say it's optimizing for the highest accuracy rating or something like that. So yeah, in that case it makes sense, that is not rating the fraudulent transactions as heavily as it's rating the non-fraudulent transactions in the way of searching. |
| Katie: | Yeah, so classifying everything as a majority case is not a crazy thing to do. On the other hand, you can see how that's not particularly useful to you if what you're trying to do is actually find the people who have the disease or actually find the fraudulent transactions. |
| Ben: | Mm hmm. |
| Katie: | So… first thing that we should point out, is that, this is one of the reasons that you need to be a little bit careful sometimes with which metric you use, when you're trying to optimize these machine-learning algorithms, so accuracy is one of the classic ones that can make you feel really good if you have in balanced classes, because a lot of times it'll tell you... I'm just going to classify everything as the majority and then accuracy looks pretty good, other metrics like the area under the ROC curve are not always as prone to this... to this problem. So first thing is, if you know that this is something that you're dealing with, think a little bit about the metrics, that you want to use and don't let accuracy give you a false sense of security. |
| Ben: | Okay. |
| Katie: | So... second thing is now what do you want to do about it, if you have this problem? |
| Ben: | Right, yeah, that was my next question. |
| Katie: | Yeah, so, a few different ideas and we'll get to SMOTE in a second, but some of the things that are a little bit simpler. And it works not too badly, so what is it you can either up-sample your minority class so you can down pay for your majority class. So you can artificially get rid of cases the majority class, so that you end up with something that's a little bit more balanced or those smaller... or similarly you can say if you want to have 10x the statistics for your majority class... what you have right now... just take each of those rows in your minority class and enter it into your training set 10 times or something. |
| Ben: | Oh, so basically, just duplicate your data. |
| Katie: | Yeah, yeah. And there's different people who’ve done different investigations of exactly what's the best way to do, the upsampling and downsampling, but… you know… that’s the basic idea. Another thing you can do is sometimes these algorithms will support different weights for different kinds of mistakes that the algorithm could be making. So you might say something like... if I let a fraudulent transaction go through, that's one kind of mistake. |
| Ben: | Like that’s really bad? |
| Katie: | Yeah, if I accidentally take a... a legitimate transaction I block it, that's a different kind of mistake, and maybe the cost for those two mistakes are not the same. So… maybe… the typical cost for letting a fraudulent transaction go through is $1,000 and the typical cost for accidentally placing a hold on what was actually a perfect fine transaction is $10. So I’m willing to make a hundred of one kind of mistakes for 10 of the other. |
| Ben: | Of course, unfortunately banks would not… will not factor in the user's’ frustration in any way other than just as some kind of monetary value of how… how likely... maybe they are to close their account or something. |
| Katie: | That's probably right. |
| Ben: | So yeah, that's a bummer. |
| Katie: | Yeah, but a lot of these algorithms then... what the inside of the algorithm is trying to do is trying to optimize some kind of cost function or maximize some kind of you know… a new benefit that is calculating and so then you can incorporate those weights into that function and then it will learn to kind of... air may be more on one side or the other, and that can help you give... give yourself a little bit more of a handle for saying, “no it's very important to me that I... not make the mistake of... missing my minority class examples when they show up.” So that's another thing you can do. |
| Ben: | Yeah, it sounds like although a lot of these algorithms can be very powerful even they’re just right out of the box, they do make certain assumptions and this is maybe one of the assumptions that a lot of them make and it's really important to know what those assumptions are going in before you use something and then you get burned. |
| Katie: | Yeah, so what you mean is that... is that... yeah, the naively out of the box... these algorithms will treat all kinds of mistakes as kind of... equally costly but that's... that's not necessarily the case. Okay, so those are two different things that we can think of off the top of our head, over / under sampling and change around the class weights. SMOTES is something that's a little bit different and it's kind of cool and it seems to... at least in the cases that I was reading about in the paper, it seems to usually work better than than either of those two things. And so the idea of SMOTES, is a little bit hidden in the name, Synthetic Minority Oversampling Technique. |
| Ben: | Synthetic Minority Oversampling Technique. So it’s a technique for synthetically oversampling your minority class? |
| Katie: | Yeah, that's fair. That's fair. So we're starting with the idea of oversampling, so we want to generate for ourselves extra examples of our minority class, so we want to boost the statistics of sample that we have available to ourselves about the minority class. And a simple oversampling would be... I'm just going to repeatedly train over and over on the same examples. And you know... one of the things that can... that can result when you do this is that... your algorithm just learns very specifically what your minority class examples look like and so, it just drills down to those little pockets of a thing that says like this is... this is definitely a minority and it hasn't learned anything that’s is very generalizable, it's just really memorized... you know... these few examples that has to learn from. |
| Ben: | Yeah. So it says ah yes, when I see a Home Depot transaction for $47.16, I know that that one was fraudulent. |
| Katie: | Yeah, especially when that happens on a Tuesday, and the area code starts with a 3. Yeah, it can learn all kinds of things that are not particularly insightful but they can make it think that it's very smart. So what you want to do is you want to give it more minority cases but ones that look similar to the ones that you're sure of but not exactly the same. |
| Ben: | So like representative but not duplicates? |
| Katie: | Exactly, and so the… the ‘S’ in Synthetic is we are generating these synthetic minority examples that are sort of inspired by our real minority examples but don't look exactly the same way and here’s how the algorithm works. You have your real actual cases of your minority, so this is... this is gonna be coming from your training set. And for each one of the minority cases that you have... your take that sort of point in space and then you're going to find its 5 nearest neighbors that are also of the minority class then you're going to randomly pick one of those 5 and you know this 5 is a little bit... 5 is the number that they used for this particular implementation but you can imagine that's kind of a free perimeter but just go with me here. So... |
| Ben: | So the picture in my head is I’ve got a point that I'm thinking about and then I look at all of the points around it and I find the five Points that are closest to it in this kind of like... almost like a scatter plot is what I'm seeing in my head. |
| Katie: | Yes the five points of the same class. That's right. |
| Ben: | Got it, okay. And these are all the fraudulent transactions or the people who are diagnosed with the disease? |
| Katie: | Exactly, exactly. So you have these five extra points that you've identified and you randomly pick one of them, and then you can imagine almost the line segment that connects sort of your original point and then the one of the five that you’ve picked. |
| Ben: | Okay, so I got a line. |
| Katie: | And that line is gonna have a distance and is going to have a direction and what you... what you then do is you randomly pick a number between 0 & 1 and you imagine that random number is kind of a slider that goes along that line segment. So if it’s 0, it's maybe all the way at the original point, if it's one, it's all the way at the... at the point that you've selected as a pair but it's going to be random where along that segment it goes. |
| Ben: | Okay, so that’s my new point. |
| Katie: | That's your new point is what's given to you as the point along that line segment by this sort of random multiplier. |
| Ben: | So if we don't want to generate a whole bunch of new points, then I can just do that over and over and over again, and none of the points are really going to be the same as any of the original points, they're going to be very representative though because you're taking two that are close to each other and you're putting some... that you're putting another point somewhere randomly in between those two points. |
| Katie: | Right, as kind of a compromise between these cases that you... that you know are true minority cases you're going to come up with something that hopefully looks something... like something is in between them literally. |
| Ben: | And the reason I imagine that you want to do something like five points, the five nearest neighbors points if you just do the closest point, then you're going to basically be drawing points along the line... along one straight line or some kind of lightning like shape or something like that, it won't necessarily be as representative within the space. |
| Katie: | Yes, you want to inject some randomness in all the ways that make sense... so one of the things is let’s say you want to up-sample your minority class by a factor of ten. So you don't necessarily want to go up to or... you might be fine going up to the ten nearest neighbors but you could imagine that maybe the five nearest neighbors are actually going to give you something that is reasonably consistent with your original point, so you want to try to keep the number of nearest neighbors kind of under control, but at the same time, if you have ten synthetic data points that you're trying to generate and you're only taking let’s say... this point and it's one nearest neighbor then you’re just going to get a string of points like… along with this line segment that connects them, which is kind of weird. That isn't really look like “real data” and you're trying to come up with something that's a little bit of a compromise between the patterns that are introduced by this generating process and the fact that... that generating processes is also hopefully giving you something that looks reasonably like... like actual minority case examples. So you're a little bit of walking the line here between something that looks a little bit too… synthetic and something that looks too random. But... but yeah you know, they did a lot of studies basically of this... of this of sampling technique with a number of different real-world data sets to try to see if this was an effective way versus something like up sampling or changing the... changing the weights and algorithms that and found that in not literally every case does SMOTE do better, but in most cases and for most of them, at least of the ones that... that were investigated by these researchers, that seems to do quite well and you know, conceptually you can see how it has some nice features relative to some of the other options.
