| Person | Transcripts |
| :-- | :-- |
| Ben: | Hey Katie. |
| Katie: | Hi Ben. |
| Ben: | Have you ever stolen anything? |
| Katie: | Well, that’s just go right in for it, don’t you? |
| Ben: | Yeah, I did. Cuz I’d stolen something and I’ll tell you about it after we start the podcast. |
| Katie: | Okay. |
| Ben: | Alright, you’re listening to Linear Digressions. |
| Ben: | So I was in Safeway once, and you know those bulk bins, I stole one Andes mint, and then after I left the store, I felt really guilty about it. That’s all. |
| Katie: | Okay. |
| Ben: | Sorry, so, we’re talking theft of something, Katie. |
| Katie: | We’re talking about theft of machine learning models today, which are a little less tasty than Andes mints. |
| Ben: | How… I didn’t know we could steal those. |
| Katie: | I know, right? But this is… you know, it’s funny, I was reading this paper, and as soon as I read the abstract of the paper, I was like, ‘Of course you could do this, right?’ |
| Ben: | Interesting, okay, so like I imagine... I guess when I think about machine learning algorithms, I think about them typically as things that are already known because so many of them are open-source, right? But I… There could be a model created by a company or by somebody who wants to maintain strategic advantage and that they wouldn’t want that model to get out there because then someone else would be able to use that model and they wouldn’t have that advantage anymore. |
| Katie: | Yeah, I think that’s a really good summary of what could be going on here. So the paper I am referring to is called ‘Stealing Machine Learning Models by a Prediction API’, and this was just put out in the last month or so. And yes, so the idea here is let’s imagine that you have some kind of machine learning as a service business, and so let's imagine, let’s imagine you, Ben, are the person who runs that business. |
| Ben: | Got it, so I created this super awesome model… |
| Katie: | Yeah. |
| Ben: | And I’m exposing some kind of end point so somebody also... so all these other programs can hit my end point on my server with some query and then I'll run my model on it and I'll send them back the results. |
| Katie: | Yeah, so let's imagine that it's a simple linear model and it’s a linear model that predicts... I don't know, what do you want to predict? |
| Ben: | Let’s say income. So I guess you give me a bunch of information and then I run this information through my model and predict the person who is stated as his income. |
| Katie: | Okay, sure, so let's say that the thing you had to do to build this model was you went out and you ran a very expensive survey where you actually went to people's houses, maybe you got them to agree to some kind of reporting automatically from their bank account, even you gather this very very labor-intensive dataset. |
| Ben: | I can be very persuasive. |
| Katie: | Sure, yeah. Let’s say you just paid them. |
| Ben: | Okay. |
| Katie: | But you got out and you collected this dataset, so you have this very rich idea of all these people, their demographic attributes, and their incomes. |
| Ben: | Right. |
| Katie: | So from these, you’re building a model that says, ‘You know, here’s the coefficient that we associated with age, so that’s how much your income tends to change with your age. Here;s a coefficient that associated with your gender, with your industry, with how much education you have, whatever.’ |
| Ben: | Yeah, now let’s imagine that this model is very very successful, it's a very good model, it's better than maybe any model out there for predicting this stuff, and rather than making an open source project I decide you know what, I'm going to monetize this. So I create that service and I allow people to submit information and I run it through my model, I send them back result, and maybe I charge them like... I don't know... $0.01 for every time they run it through model. |
| Katie: | Yeah, bingo. So then what I can do as an adversary... there are several different things that I could potentially steal here. The easiest one to steal is the actual model itself. So what I can do is... let’s imagine... this is an oversimplification, but let’s imagine it's a one-dimensional linear model, so it's basically a line, Y equals MX plus b, right? |
| Ben: | Yeah. |
| Ben: | So let's say, and then let's say that you return a prediction and... potentially some uncertainty on the prediction about someone's income. So what I can do is I can say... let’s say the particular linear relationship that we have is the... let’s say... your income only depends on your age, and I don't know the relationship between your income and your age but I know it’s just those two variables. So then I might have somebody who is 30 years old and I say what's their income. Oh, that's $60,000. |
| Katie: | Cool, and now I have someone who's 50 years old, what's their income? |
| Ben: | $100,000.00 |
| Katie: | Okay, so now I have two points, I have an age and an income for both of those points, and I said by design, that it's just a simple y equals MX plus b equation, I can now solve for the complete equation of that line, and I can interpolate now for every point along that line, what their income is going to be, just based on those two data points. A completely reconstruct of your model, I just stole your model from you. |
| Ben: | Ah. |
| Katie: | So there's no reason why I would have to ask you anymore and pay a penny every time, I can recreate all of the... I can recreate the model now. And so that's basically… |
| Ben: | That’s a really really simplistic example. |
| Katie: | It is, but for a linear model, if you know... like all of the.... all of the features that the model is built upon, basically the idea is... if you have some idea of what the input space is and then you just ask... it might be D dimensional but then if you make D + 1 queries on it, you can reconstruct the entire thing, it's just like it's like a linear algebra statement almost that... you know, if it obeys those rules, you can reconstruct the entire model. |
| Ben: | Yeah, that makes sense. And then in more complicated examples, you might need to pay more pennies to reconstruct this and you might have more error. But basically what you are talking about is reverse engineering. You put a bunch of input in, you look at the output, and you say like ‘how do I think this might be working under the hood?’, right? To transform these inputs into these outputs. And then once you can kind of a good guess of the way it's working, you validate it with a couple more pieces of input, and potentially you've stolen either the exact model or something very close. |
| Katie: | There’re different types of models that are easier or harder to steal. So one of the things that I assumed going into this is that I know that it's a linear model. And I would necessarily know that the you could have something like a neural net or a decision tree, and each of those is going to have a different complexity in terms of how hard it's going to be for me to reconstruct it. For example, the decision tree is harder because it's not linear, you can be making like... weird, very sharp cut-offs in a way where I would need to take more data to find those discontinuities. So they have... they have different examples for each of these different algorithms, what they actually did to write this paper was they built models on some of these popular services and then tried to steal their own models and demonstrate that you could do it with... you know, the various algorithms that are kind of (inaudible). |
| Ben: | That’s so interesting. |
| Katie: | Yeah, and one of the other things that I should say is that predict the income kind of a continuous problem, but they also do it for classification as well. So many of these classification algorithms that will return to you a prediction and also an uncertainty on that prediction, so they might say like ‘oh, we think that this is the dog, and we're very confident in that prediction, or we think that this is a house, and we're not so confident.’ And especially if you have those confidence intervals, then that helps a lot to it in terms of... like if you're thinking of yourself as the adversary, you would like to have that extra piece of information about how confident the model is, because it makes you a lot, it makes it a lot easier for you to like basically tell where you need to take more data, or where we have things pretty well mapped out. And then the other thing that I had was really crazy about this paper is in certain cases, this is harder, but in certain cases, remember I said you have this expensive data set that you went out and collected and use that as the underlying data when you were training your model? |
| Ben: | Right. |
| Katie: | In certain cases, I can even reconstruct examples from your original training data based on queries of the model, and this I do not understand quite as much, I didn't have a chance to really dig into this part of the paper, but they were able to basically regenerate examples from their training data sometimes, not always, this... this... this is harder, but it is possible that even the data itself could be compromised. |
| Ben: | Oh, that is really fascinating, that is crazy. |
| Katie: | So, one last thing to slightly pivot before we sign off, which is a little bit of an addendum to our episode that we did last week about regularization, right? |
| Ben: | Mm hmm. |
| Katie: | I usually try to do this at the beginning of an episode, but then I forgot. SO, I got a really good comment on Twitter which is referring to the fact that I actually overlooked an important reason why you might even do regularization that we should talk about, so let me give.. first of all, some credit to Amir Bernama. |
| Ben: | Good said. |
| Katie: | Who pointed this out. |
| Ben: | And just really quick summary, what's regularization again? |
| Katie: | Oh right, so a regularization is the idea that you have an aspect of your algorithm when you're actually training a machine learning algorithm, like a supervised classifier, you have a term that penalizes the complexity of the model that you’re building, we effectively end up throwing out features if they don't seem to be adding a lot to... to the performance of the model. |
| Ben: | Right, so that allows you to make your model run faster, be more performance while not necessarily changing the results that you get all that much. |
| Katie: | Yeah, so Amir kinda asked the question about like ‘Why didn't you say this? As some of the important reasons why you might want to do this’. |
| Ben: | What were the things he said? |
| Katie: | Overfitting and sparsity. So overfitting is just the idea that if you have a model that has a lot of complexity to it, it can become kind of overfit, it learns not just the generals patterns in the data but sometimes the little quirks and wiggles in the data and that actually makes it and not as good of a model. It will tend to make mistakes on other cases, cuz it's learned that the training data in too detail of the way. |
| Ben: | Right, your training data is supposed to be a sample of a larger dataset, but because it's going to have a finite size, and kind of reasonable size, it's going to have those nooks and crannies that don't necessarily exist in the phenomenon that you're trying to study. |
| Katie: | Yeah, so if your model gets very complex, sometimes it ends up fitting those nooks and crannies which is not what you wanted to do. |
| Ben: | Yeah. |
| Katie: | So controlling the complexity of the model helps control overfitting. And then the second thing that Amir mentioned was sparsity. So sparsity, yeah, that's when you have data where it tends to, I kind of think of it is when you have data that's mostly zeros, instead of ones, so classic example is maybe Amazon. Data is very very sparse, because for each person they only buy... even if they buy tons of stuff, it's still only going to be a tiny fraction of all the stuff that's available on Amazon, and for each of the products, even if it's a very popular product, it's only going to be bought by a tiny fraction of the users, so that would be an example of where you have very sparse data. And so sometimes you can especially... when you have you know, kind of hashtag Big Data, it tends to very often be... be kind of sparse, so we can be really big, but there isn't a whole lot of information in there, and so overfitting can help you deal with that a little bit, you can still dump that really big data set into an algorithm and if there's some regularization, then I can help you trim away, some of that stuff that doesn't seem to have a whole lot of information at their earliest information that’s important for the things that you're interested in. So I think that's what Amir meant by sparsity, sparsity sometimes... people are thinking of different aspects of data when they say that, so that was a little bit my interpretation, but that is a very good point as well.
